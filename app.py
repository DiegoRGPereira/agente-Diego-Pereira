import streamlit as st
import google.generativeai as genai
import plotly.graph_objects as go
from PIL import Image

# --- 1. CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(page_title="Diego Pereira | Agente Virtual", page_icon="üè≠", layout="wide")

# CSS para visual limpo e profissional (Estilo React/Moderno)
st.markdown("""
<style>
    .stApp { background-color: #f8f9fa; color: #212529; } /* Fundo claro profissional */
    [data-testid="stSidebar"] { background-color: #1e293b; color: white; }
    .stChatInput textarea { background-color: white; color: #333; border: 1px solid #ccc; }
    .css-1d391kg { padding-top: 1rem; }
    .status-badge {
        background-color: #10b981; color: white; padding: 4px 10px;
        border-radius: 12px; font-size: 11px; font-weight: 600; text-transform: uppercase;
    }
    h1, h2, h3 { font-family: 'Helvetica Neue', sans-serif; }
</style>
""", unsafe_allow_html=True)

# --- 2. SEGURAN√áA & API ---
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("‚ö†Ô∏è Configure a GEMINI_API_KEY nos Secrets do Streamlit.")

# --- 3. C√âREBRO DA IA (PROMPT) ---
system_instruction = """
VOC√ä √â O 'AGENTE VIRTUAL DIEGO PEREIRA'.
IDENTIDADE: Engenheiro de Produ√ß√£o Mec√¢nica, Especialista em Lean (Green Belt) e Dados.
REGRAS T√âCNICAS:
1. AN√ÅLISE VISUAL: Se receber uma imagem, analise como um engenheiro de ch√£o de f√°brica (procure falhas, desperd√≠cios ou dados em gr√°ficos).
2. MES/OEE: O problema real √© o apontamento manual e microparadas. Use OEE para diagn√≥stico.
3. EXPERI√äNCIA: 3M/Lear/Yamaha (Ch√£o de f√°brica). ATUAL: BIP/Petrobras (BPO/Planejamento).
4. OBJETIVO: Prove que o Diego une engenharia tradicional com inova√ß√£o.
CONTATO: diegogpereira@gmail.com
"""

# Usando o modelo Flash que √© r√°pido e aceita imagens
model = genai.GenerativeModel(model_name="gemini-1.5-flash", system_instruction=system_instruction)

# --- 4. BARRA LATERAL (PERFIL) ---
with st.sidebar:
    # Cabe√ßalho do Perfil
    col1, col2 = st.columns([1, 3])
    with col1:
        st.markdown("üßë‚Äçüîß", unsafe_allow_html=True) # Pode trocar por st.image se tiver
    with col2:
        st.markdown("**Diego Pereira**")
        st.caption("Lean Specialist")
    
    st.markdown('<div style="margin-top:10px;"><span class="status-badge">Open to Work</span></div>', unsafe_allow_html=True)
    st.divider()
    
    # Gr√°fico Radar
    st.markdown("### Compet√™ncias")
    categories = ['Lean / Six Sigma', 'Gest√£o de Projetos', 'MES / OEE', 'Python / Dados', 'Lideran√ßa', 'SAP']
    r_values = [10, 9, 8, 7, 9, 8]

    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=r_values, theta=categories, fill='toself', name='Diego',
        line_color='#3b82f6', fillcolor='rgba(59, 130, 246, 0.3)'
    ))
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 10], showticklabels=False, linecolor='gray'), bgcolor='rgba(0,0,0,0)'),
        showlegend=False, paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white', size=10), margin=dict(l=20, r=20, t=10, b=10), height=250
    )
    st.plotly_chart(fig, use_container_width=True)
    
    st.info("üí° **Diferencial:** Uno a metodologia Lean tradicional com an√°lise de dados moderna (Python/IA).")
    st.markdown("üìß diegogpereira@gmail.com")

# --- 5. √ÅREA DE CHAT ---
st.title("üè≠ Engenharia 4.0 | Diego Pereira")
st.markdown("Discuta problemas de **Ch√£o de F√°brica, OEE e Lean** ou envie uma imagem para an√°lise.")

# Inicializar Hist√≥rico
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "model", "content": "Ol√°! Sou a vers√£o virtual do Diego. Posso analisar seus processos ou discutir estrat√©gias de Lean Manufacturing. Como posso ajudar?"}
    ]

# Mostrar Mensagens Antigas
for message in st.session_state.messages:
    avatar = "ü§ñ" if message["role"] == "model" else "üë∑"
    with st.chat_message(message["role"], avatar=avatar):
        # Se tiver imagem na mensagem, mostra
        if "image" in message:
            st.image(message["image"], width=200)
        st.markdown(message["content"])

# --- 6. √ÅREA DE INPUT (TEXTO + IMAGEM) ---
# Upload de arquivo
uploaded_file = st.file_uploader("üìé Anexar imagem (Gr√°fico, Pe√ßa, Tabela)", type=["jpg", "png", "jpeg"], label_visibility="collapsed")

if prompt := st.chat_input("Digite sua d√∫vida t√©cnica..."):
    # 1. Preparar conte√∫do do usu√°rio
    user_content = [prompt]
    image_data = None
    
    # Se tiver imagem, processa
    if uploaded_file:
        image_data = Image.open(uploaded_file)
        user_content.append(image_data)
        st.session_state.messages.append({"role": "user", "content": prompt, "image": image_data})
        with st.chat_message("user", avatar="üë∑"):
            st.image(image_data, width=200)
            st.markdown(prompt)
    else:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üë∑"):
            st.markdown(prompt)

    # 2. Gerar Resposta (Streaming)
    with st.chat_message("model", avatar="ü§ñ"):
        try:
            # Se tiver imagem, usa generate_content (sem hist√≥rico por enquanto para simplificar)
            if image_data:
                response = model.generate_content(user_content, stream=True)
            else:
                # Se for s√≥ texto, usa chat history
                chat = model.start_chat(history=[
                    {"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]} 
                    for m in st.session_state.messages if "image" not in m
                ])
                response = chat.send_message(prompt, stream=True)
            
            # Efeito de digitar na tela
            full_response = st.write_stream(response)
            
            # Salvar resposta no hist√≥rico
            st.session_state.messages.append({"role": "model", "content": full_response})
            
        except Exception as e:
            st.error(f"Erro ao processar: {e}")
