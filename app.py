import streamlit as st
import google.generativeai as genai
import plotly.graph_objects as go

# --- 1. CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(page_title="Diego Pereira | Agente Virtual", page_icon="üè≠", layout="wide")

# CSS Estilo "React Clean"
st.markdown("""
<style>
    .stApp { background-color: #f8f9fa; color: #212529; }
    [data-testid="stSidebar"] { background-color: #1e293b; color: white; }
    .stChatInput textarea { background-color: white; color: #333; border: 1px solid #ddd; }
    .status-badge {
        background-color: #10b981; color: white; padding: 4px 10px;
        border-radius: 12px; font-size: 11px; font-weight: 600; text-transform: uppercase;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. SEGURAN√áA ---
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("‚ö†Ô∏è Configure a GEMINI_API_KEY nos Secrets do Streamlit.")

# --- 3. C√âREBRO (PROMPT INJETADO) ---
# O Gemini Pro antigo n√£o aceita 'system_instruction' direto, ent√£o usamos este texto oculto
system_instruction_text = """
VOC√ä √â O 'AGENTE VIRTUAL DIEGO PEREIRA'.
IDENTIDADE: Engenheiro de Produ√ß√£o Mec√¢nica, Especialista em Lean (Green Belt) e Dados.
REGRAS DE INTERA√á√ÉO:
1. Responda como um engenheiro experiente de ch√£o de f√°brica (Gemba).
2. MES/OEE: O problema real √© o apontamento manual e microparadas. Use OEE para diagn√≥stico.
3. EXPERI√äNCIA: 3M/Lear/Yamaha (Ch√£o de f√°brica). ATUAL: BIP/Petrobras (BPO/Planejamento - n√£o misturar com MES).
4. OBJETIVO: Prove que o Diego une engenharia tradicional com inova√ß√£o.
CONTATO: diegogpereira@gmail.com
"""

# Usamos o modelo PRO (Texto apenas) que √© 100% est√°vel
model = genai.GenerativeModel("gemini-pro")

# --- 4. BARRA LATERAL (PERFIL) ---
with st.sidebar:
    col1, col2 = st.columns([1, 3])
    with col1:
        st.write("üßë‚Äçüîß")
    with col2:
        st.markdown("**Diego Pereira**")
        st.caption("Lean Specialist")
    
    st.markdown('<div style="margin-top:10px;"><span class="status-badge">Open to Work</span></div>', unsafe_allow_html=True)
    st.divider()
    
    # Gr√°fico Radar
    categories = ['Lean / Six Sigma', 'Gest√£o de Projetos', 'MES / OEE', 'Python / Dados', 'Lideran√ßa', 'SAP']
    r_values = [10, 9, 8, 7, 9, 8]

    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=r_values, theta=categories, fill='toself', name='Diego',
        line_color='#3b82f6', fillcolor='rgba(59, 130, 246, 0.3)'
    ))
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 10], showticklabels=False, linecolor='gray'), bgcolor='rgba(0,0,0,0)'),
        showlegend=False, paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white', size=10), margin=dict(l=20, r=20, t=10, b=10), height=250
    )
    st.plotly_chart(fig, use_container_width=True)
    st.info("üí° **Diferencial:** Uno a metodologia Lean tradicional com an√°lise de dados moderna.")
    st.markdown("üìß diegogpereira@gmail.com")

# --- 5. CHAT ---
st.title("üè≠ Engenharia 4.0 | Diego Pereira")
st.markdown("Discuta problemas de **Ch√£o de F√°brica, OEE e Lean** com o assistente virtual.")

# Inicializa Hist√≥rico com o "Truque da Inje√ß√£o"
if "messages" not in st.session_state:
    st.session_state.messages = [
        # Mensagem oculta com as regras
        {"role": "user", "content": f"Aja estritamente conforme estas regras: {system_instruction_text}. Se entendeu, diga apenas 'Ol√°'."},
        {"role": "model", "content": "Ol√°! Sou a vers√£o virtual do Diego. Vamos discutir estrat√©gias de Lean Manufacturing e efici√™ncia?"}
    ]

# Mostra as mensagens (Pulando a primeira que √© a regra oculta)
for i, message in enumerate(st.session_state.messages):
    if i == 0: continue 
    avatar = "ü§ñ" if message["role"] == "model" else "üë∑"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

if prompt := st.chat_input("Digite sua d√∫vida t√©cnica..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="üë∑"):
        st.markdown(prompt)

    with st.chat_message("model", avatar="ü§ñ"):
        try:
            # Envia hist√≥rico completo para manter o contexto
            chat = model.start_chat(history=[
                {"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]} 
                for m in st.session_state.messages[:-1]
            ])
            response = chat.send_message(prompt)
            st.markdown(response.text)
            st.session_state.messages.append({"role": "model", "content": response.text})
            
        except Exception as e:
            st.error(f"Erro de conex√£o: {e}")
